{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 182] The operating system cannot run %1. Error loading \"c:\\Users\\kriselda\\miniconda3\\envs\\dl\\lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load,dump\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CountVectorizer\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m  Image_Caption,get_tier\n",
      "File \u001b[1;32mc:\\Users\\kriselda\\source\\repos\\demo\\utils.py:14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m maxsize\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwhisper\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AudioSegment\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pad_sequences, to_categorical\n",
      "File \u001b[1;32mc:\\Users\\kriselda\\miniconda3\\envs\\dl\\lib\\site-packages\\whisper\\__init__.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Optional, Union\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_audio, log_mel_spectrogram, pad_or_trim\n",
      "File \u001b[1;32mc:\\Users\\kriselda\\miniconda3\\envs\\dl\\lib\\site-packages\\torch\\__init__.py:128\u001b[0m\n\u001b[0;32m    126\u001b[0m     err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(last_error)\n\u001b[0;32m    127\u001b[0m     err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m     is_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 182] The operating system cannot run %1. Error loading \"c:\\Users\\kriselda\\miniconda3\\envs\\dl\\lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import os \n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model,optimizers\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Dropout,Embedding,Add\n",
    "from tqdm import tqdm\n",
    "from pickle import load,dump\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from utils import  Image_Caption,get_tier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##import whisper \n",
    "##model = whisper.load_model(\"medium\")\n",
    "##result = model.transcribe(\"sample.mp4\",language='en')\n",
    "## tiny 70s\n",
    "## base 125s\n",
    "## small 403 s  #acceptable\n",
    "## medium 1178\n",
    "## large 2343s\n",
    "\n",
    "# print(len(result['segments']))\n",
    "# # for k,i in result['segments'][1].items():\n",
    "# #     print(f'{k}\\t:\\t{i}')\n",
    "\n",
    "# for it in result['segments']:\n",
    "#     print(f'[{it[\"start\"]} --> {it[\"end\"]}]\\t{it[\"text\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model/word2index.pkl', 'rb') as pickle_file:\n",
    "    word_index_Mapping = load(pickle_file)\n",
    "\n",
    "word_index_Mapping['init'] = len(word_index_Mapping) + 1\n",
    "index_word_Mapping = dict(map(reversed,word_index_Mapping.items()))\n",
    "vocab_size = len(word_index_Mapping) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_caption_length = 84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#word embedding\n",
    "glove_dir='glove/glove.6B.300d.txt'\n",
    "embeddings_index = {}\n",
    "embeddings_index_all = {}\n",
    "f = open(glove_dir,encoding=\"utf-8\")\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:],dtype='float32')\n",
    "    embeddings_index_all[word] = coefs\n",
    "    if word in word_index_Mapping.keys():\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "f.close()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "embedding_dim = 300\n",
    "embedding_matrix = np.zeros((vocab_size,embedding_dim))\n",
    "\n",
    "for word, i in word_index_Mapping.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    image_input = Input(shape=(2048,))\n",
    "    x = Dropout(0.4)(image_input)\n",
    "    image_encode = Dense(256,activation='relu')(x)\n",
    "\n",
    "    text_input = Input(shape=(max_caption_length,))\n",
    "    x = Embedding(vocab_size,embedding_dim,mask_zero=True)(text_input)\n",
    "    x = Dropout(0.4)(x)\n",
    "    text_encode = LSTM(256)(x)\n",
    "\n",
    "    decoder_input = Add()([image_encode,text_encode])\n",
    "    x = Dense(256,activation='relu')(decoder_input)\n",
    "    output = Dense(vocab_size,activation='softmax')(x)\n",
    "    model = Model(inputs=[image_input,text_input],outputs=output)\n",
    "\n",
    "\n",
    "    model.layers[2].set_weights([embedding_matrix])\n",
    "    model.layers[2].trainable = False\n",
    "\n",
    "    optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=optimizer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model/model--434--3.34.h5'\n",
    "model = load_model(model_path,compile=False)\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer=optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "femodel = tf.keras.applications.inception_v3.InceptionV3(weights='imagenet')\n",
    "incp_model_feature = Model(femodel.input,femodel.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_cp = Image_Caption(images_dir='',\n",
    "                      model = model,\n",
    "                      fe_model=incp_model_feature,\n",
    "                      w2v = embeddings_index_all,\n",
    "                      tier = get_tier('tier1.txt'),\n",
    "                      word_index_Mapping=word_index_Mapping,\n",
    "                      index_word_Mapping=index_word_Mapping,\n",
    "                      max_caption_length=max_caption_length,\n",
    "                      vocab_size=vocab_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_cp.caption_video('sample3.mp4',is_url=False,url='https://youtu.be/ffyKY3Dj5ZE?list=RDQMmFbcybekSiU',subtitles=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "audio_file= open(\"lmm.mp4\", \"rb\")\n",
    "transcript = client.audio.transcriptions.create(\n",
    "  model=\"whisper-1\", \n",
    "  file=audio_file\n",
    ")\n",
    "print(type(transcript.text))\n",
    "print(transcript.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
