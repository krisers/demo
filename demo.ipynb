{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model,optimizers\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Dropout,Embedding,Add\n",
    "from tqdm import tqdm\n",
    "from pickle import load,dump\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from utils import  Image_Caption,get_tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model/word2index.pkl', 'rb') as pickle_file:\n",
    "    word_index_Mapping = load(pickle_file)\n",
    "\n",
    "word_index_Mapping['init'] = len(word_index_Mapping) + 1\n",
    "index_word_Mapping = dict(map(reversed,word_index_Mapping.items()))\n",
    "vocab_size = len(word_index_Mapping) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_caption_length = 84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#word embedding\n",
    "glove_dir='glove/glove.6B.300d.txt'\n",
    "embeddings_index = {}\n",
    "embeddings_index_all = {}\n",
    "f = open(glove_dir,encoding=\"utf-8\")\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:],dtype='float32')\n",
    "    embeddings_index_all[word] = coefs\n",
    "    if word in word_index_Mapping.keys():\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "f.close()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "embedding_dim = 300\n",
    "embedding_matrix = np.zeros((vocab_size,embedding_dim))\n",
    "\n",
    "for word, i in word_index_Mapping.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    image_input = Input(shape=(2048,))\n",
    "    x = Dropout(0.4)(image_input)\n",
    "    image_encode = Dense(256,activation='relu')(x)\n",
    "\n",
    "    text_input = Input(shape=(max_caption_length,))\n",
    "    x = Embedding(vocab_size,embedding_dim,mask_zero=True)(text_input)\n",
    "    x = Dropout(0.4)(x)\n",
    "    text_encode = LSTM(256)(x)\n",
    "\n",
    "    decoder_input = Add()([image_encode,text_encode])\n",
    "    x = Dense(256,activation='relu')(decoder_input)\n",
    "    output = Dense(vocab_size,activation='softmax')(x)\n",
    "    model = Model(inputs=[image_input,text_input],outputs=output)\n",
    "\n",
    "\n",
    "    model.layers[2].set_weights([embedding_matrix])\n",
    "    model.layers[2].trainable = False\n",
    "\n",
    "    optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=optimizer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model/model--434--3.34.h5'\n",
    "#model = get_model()\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "femodel = tf.keras.applications.inception_v3.InceptionV3(weights='imagenet')\n",
    "incp_model_feature = Model(femodel.input,femodel.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_cp = Image_Caption(images_dir='',\n",
    "                      model = model,\n",
    "                      fe_model=incp_model_feature,\n",
    "                      w2v = embeddings_index_all,\n",
    "                      tier = get_tier('tier1.txt'),\n",
    "                      word_index_Mapping=word_index_Mapping,\n",
    "                      index_word_Mapping=index_word_Mapping,\n",
    "                      max_caption_length=max_caption_length,\n",
    "                      vocab_size=vocab_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_cp.caption_video('sample.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
